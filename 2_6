import pandas as pd
from numpy import loadtxt
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

data=pd.read_csv('/diabetes.csv')
X=data.iloc[:,0:8]
y=data.iloc[:,8]

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)

models=[]

models.append(('LinearRegression',LinearRegression()))
# models.append('LogisticRegression',LogisticRegression())
# models.append('XGBoost',XGBClassifier(eta=0.01,gamma=10))
models.append(('DecisionTree',DecisionTreeClassifier()))
# models.append('SVM',SVC())

import time
for name,model in models:
    start_time=time.time()
    model.fit(X_train,y_train)
    y_pred=model.predict(X_test)
    predictions=[round(value) for value in y_pred]


accuracy=accuracy_score(predictions,y_test)
print("Accuracy is %.2f"%accuracy,name)
print("-----%s-----"%(time.time()-start_time))

import pandas as pd
df = pd.read_csv('/dataset.csv')
x_train = df.drop('0', axis=1)
y_train = df['0']

from sklearn.tree import export_text

for name, model in models:
    start_time = time.time()
    model.fit(x_train, y_train)
    y_pred = model.predict(x_train)
    predictions = [round(value) for value in y_pred]

    if name == 'DecisionTree':
        tree_rules = export_text(model, feature_names=list(x_train.columns))
        print(tree_rules)


import matplotlib.pyplot as plt

plt.scatter(df['60'],df['44'])
plt.xlabel('Glucose')
plt.ylabel('Diabetes')
